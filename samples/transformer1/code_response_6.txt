```python
class AnimationVideo(VoiceoverScene):

    def play_scene_1(self):
        # Implementation: Setting dark background
        self.camera.background_color = "#000000"
        # Implementation: Part 1
        with self.voiceover(text="Let's explore the fascinating world of Transformers in machine learning.") as tracker:
            # Implementation: Show the text "Transformers in ML" at the top-center of the screen in a large, bold, white font, using a sans-serif font like Arial, size 48pt.
            # Thinking: Top-center position can be achieved by using UP direction with some scaling to avoid extreme top.
            title_text = Text("Transformers in ML", font="Arial", font_size=48, weight=BOLD).to_edge(UP)
            self.play(Write(title_text))
            self.wait(tracker.duration / 4)

            # Implementation: After a brief pause, start moving the text smoothly towards the left side of the screen, taking about 2 seconds for the transition.
            # Thinking: Left side position can be achieved by using LEFT direction with some scaling to avoid extreme left.
            self.play(title_text.animate.to_edge(LEFT), run_time=tracker.duration / 2)
            self.wait(tracker.duration / 4)

            # Implementation: Once the text has moved to the left, display a simple rectangular block representing an RNN in the center of the screen.
            # Thinking: Center of screen is at ORIGIN
            rnn_block = Rectangle(width=2, height=1).move_to(ORIGIN)
            self.play(Create(rnn_block))

            # Implementation: Add a labeled arrow marked "Input" entering the RNN block from the left.
            # Thinking: Left of RNN block can be calculated using get_left() method.
            input_arrow = Arrow(start=rnn_block.get_left() + LEFT * 2, end=rnn_block.get_left(), buff=0).set_color(WHITE)
            input_label = Text("Input", font="Arial", font_size=24).next_to(input_arrow, DOWN)
            self.play(Create(input_arrow), Write(input_label))

            # Implementation: Add another labeled arrow exiting the block to the right marked as "Output".
            # Thinking: Right of RNN block can be calculated using get_right() method.
            output_arrow = Arrow(start=rnn_block.get_right(), end=rnn_block.get_right() + RIGHT * 2, buff=0).set_color(WHITE)
            output_label = Text("Output", font="Arial", font_size=24).next_to(output_arrow, DOWN)
            self.play(Create(output_arrow), Write(output_label))

            # Implementation: Animate a small circle moving along the input arrow, through the RNN block, and out along the output arrow, taking about 2 seconds to complete the path, depicting sequential processing.
            circle = Circle(radius=0.1, fill_opacity=1, color=WHITE).move_to(input_arrow.get_start())
            self.play(Create(circle))
            self.play(MoveAlongPath(circle, input_arrow), run_time=tracker.duration / 4)
            self.play(MoveAlongPath(circle, Line(input_arrow.get_end(), output_arrow.get_start())), run_time=tracker.duration / 4)
            self.play(MoveAlongPath(circle, output_arrow), run_time=tracker.duration / 4)
            self.play(FadeOut(circle))

        # Cleaning: No object should be cleared

        # Implementation: Part 2
        with self.voiceover(text="Before Transformers, models like Recurrent Neural Networks or RNNs processed data sequentially, one element at a time.") as tracker:
            # Implementation: Keep the RNN block from the previous part in the center.
            # Implementation: Add a label "Recurrent Neural Network" below the RNN block using white, Arial font, size 24pt.
            rnn_label = Text("Recurrent Neural Network", font="Arial", font_size=24).next_to(rnn_block, DOWN)
            # Implementation: Ensure the label is horizontally centered with the RNN block and there's enough space between them so they don't overlap.
            rnn_label.align_to(rnn_block, DOWN)
            self.play(Write(rnn_label))
            self.wait(tracker.duration)

        # Cleaning: Clear all objects
        self.clear()

    def play_scene_2(self):
        # Implementation: Setting dark background
        self.camera.background_color = "#000000"
        # Implementation: Part 1
        with self.voiceover(text="This sequential nature made RNNs slow, especially for long sequences.") as tracker:
            # Implementation: Display the sentence "This is a long sentence" at the top-left of the screen, with each word spaced apart by about 20 pixels, using white Arial font, size 24pt.
            # Thinking: Top-left position can be achieved by using UP and LEFT direction with some scaling.
            sentence = Text("This is a long sentence", font="Arial", font_size=24).to_edge(UP + LEFT)
            for i in range(len(sentence) - 1):
                sentence[i].next_to(sentence[i+1], LEFT, buff=0.2)
            self.play(Write(sentence))

            # Implementation: Move the entire sentence towards the RNN block, which is positioned in the center of the screen.
            # Thinking: Center of screen is at ORIGIN
            rnn_block = Rectangle(width=2, height=1).move_to(ORIGIN)
            self.play(Create(rnn_block))

            # Implementation: Animate each word entering the RNN block sequentially, one after the other, with a 0.5-second delay between each word.
            output_rects = []
            for i, word in enumerate(sentence):
                self.play(word.animate.move_to(rnn_block.get_center() + LEFT * 0.5), run_time=tracker.duration / 8)
                self.wait(tracker.duration / 8)

                # Implementation: As each word is processed, show a corresponding output on the right side of the RNN block, represented by small grey rectangles.
                output_rect = Rectangle(width=0.5, height=0.2, fill_opacity=0.5, color=GRAY).move_to(rnn_block.get_center() + RIGHT * 0.5)
                self.play(Create(output_rect))
                output_rects.append(output_rect)

                # Implementation: For each new word processed, reduce the size of the output rectangles from previously processed words by 10% and decrease their opacity by 20%, making them less prominent.
                for j, rect in enumerate(output_rects[:-1]):
                    self.play(
                        rect.animate.scale(0.9).set_opacity(rect.opacity - 0.2),
                        output_rects[-1].animate.shift(RIGHT * 0.5 * (len(output_rects) - 1 - j))
                    )

        # Cleaning: No object should be cleared

        # Implementation: Part 2
        with self.voiceover(text="They also suffered from issues like vanishing or exploding gradients, making it hard to learn long-range dependencies in the data.") as tracker:
            # Implementation: Move the sentence and RNN block diagram towards the right side of the screen over a duration of 1 second, creating space on the left.
            # Thinking: Right side can be achieved by using RIGHT direction with some scaling.
            self.play(
                sentence.animate.to_edge(RIGHT),
                rnn_block.animate.to_edge(RIGHT),
                run_time=tracker.duration / 8
            )
            for rect in output_rects:
                self.play(rect.animate.to_edge(RIGHT), run_time=tracker.duration / 8)

            # Implementation: Display the text "Vanishing Gradient Problem" at the top-center in large, bold, white Arial font, size 48pt.
            # Thinking: Top-center can be achieved by using UP direction with some scaling.
            vanishing_text = Text("Vanishing Gradient Problem", font="Arial", font_size=48, weight=BOLD).to_edge(UP)
            self.play(Write(vanishing_text))

            # Implementation: Below this text, draw a horizontal chain of five connected rectangular blocks, each 50 pixels wide and 30 pixels high, representing the steps in backpropagation.
            blocks = []
            for i in range(5):
                block = Rectangle(width=1, height=0.6)
                blocks.append(block)

            # Implementation: The blocks should be spaced 20 pixels apart.
            for i in range(4):
                blocks[i+1].next_to(blocks[i], LEFT, buff=0.4)

            # Implementation: Apply a color gradient to these blocks, starting with dark red (#8B0000) for the first block on the right and transitioning to light pink (#FFB6C1) for the last block on the left, illustrating the diminishing strength of the gradient signal during backpropagation.
            colors = color_gradient([DARK_RED, LIGHT_PINK], 5)
            for i, block in enumerate(blocks):
                block.set_fill(color=colors[i], opacity=1)

            # Implementation: Ensure the transition is smooth, using linear interpolation between colors.
            self.play(*[Create(block) for block in blocks], run_time=tracker.duration / 2)
            self.wait(tracker.duration / 2)

        # Cleaning: Clear all objects
        self.clear()

    def play_scene_3(self):
        # Implementation: Setting dark background
        self.camera.background_color = "#000000"
        # Implementation: Part 1
        with self.voiceover(text="The game-changer was the concept of 'Attention'.") as tracker:
            # Implementation: Clear the screen of all previous elements.
            self.clear()

            # Implementation: Display the text "Attention" prominently at the top-center of the screen in a large, bold, white Arial font, size 48pt.
            # Thinking: Top-center can be achieved by using UP direction with some scaling.
            attention_text = Text("Attention", font="Arial", font_size=48, weight=BOLD).to_edge(UP)
            self.play(Write(attention_text))

            # Implementation: Below this, add a brief explanation: "Attention allows a model to focus on relevant parts of the input sequence." in white Arial font, size 24pt.
            explanation_text = Text("Attention allows a model to focus on relevant parts of the input sequence.", font="Arial", font_size=24, t2c={"Attention": YELLOW}).scale(0.8).next_to(attention_text, DOWN, buff=0.5)
            # Implementation: The explanation text should be horizontally centered and placed about 30 pixels below the "Attention" text.
            explanation_text.align_to(attention_text, direction=DOWN)
            self.play(Write(explanation_text))
            self.wait(tracker.duration)

        # Cleaning: Clear all objects
        self.clear()

        # Implementation: Part 2
        with self.voiceover(text="Instead of processing word by word, attention allows the model to look at all words at once and determine their relationships, avoiding the bottlenecks of RNNs.") as tracker:
            # Implementation: Move the "Attention" text to the top-left corner of the screen, taking 1 second for the transition.
            # Thinking: Top-left can be achieved by using UP and LEFT direction with some scaling.
            attention_text = Text("Attention", font="Arial", font_size=48, weight=BOLD).to_edge(UP + LEFT)
            self.play(Write(attention_text))

            # Implementation: Reintroduce the sentence "This is a long sentence" near the top of the screen, slightly below and to the right of the "Attention" text, with each word spaced 20 pixels apart.
            sentence = Text("This is a long sentence", font="Arial", font_size=24).next_to(attention_text, DOWN + RIGHT * 2).shift(DOWN)
            for i in range(len(sentence) - 1):
                sentence[i].next_to(sentence[i+1], RIGHT, buff=0.2)
            self.play(Write(sentence))

            # Implementation: Draw a new rectangular block labeled "Attention" below the sentence, centered horizontally.
            attention_block = Rectangle(width=2, height=1).next_to(sentence, DOWN, buff=1)
            attention_label = Text("Attention", font="Arial", font_size=24).move_to(attention_block)
            self.play(Create(attention_block), Write(attention_label))

            # Implementation: Connect all words of the sentence to this block simultaneously with lines, indicating parallel processing.
            lines = []
            for word in sentence:
                line = Line(word.get_bottom(), attention_block.get_top(), buff=0.1)
                lines.append(line)
            self.play(*[Create(line) for line in lines], run_time=tracker.duration / 4)

            # Implementation: For each word in the sentence, draw lines connecting it to other words, representing attention weights.
            attention_lines = []
            for i, word1 in enumerate(sentence):
                for j, word2 in enumerate(sentence):
                    if i != j:
                        # Implementation: Use brighter lines (#FFFFE0) for stronger connections and dimmer lines (white with 50% opacity) for weaker connections.
                        if word1.text == "sentence" and word2.text == "long":
                            line = Line(word1.get_center(), word2.get_center(), color="#FFFFE0", buff=0.1)
                        else:
                            line = Line(word1.get_center(), word2.get_center(), color=WHITE, opacity=0.5, buff=0.1)
                        attention_lines.append(line)

            # Implementation: The lines should be animated to appear in sync with the audio explanation.
            self.play(*[Create(line) for line in attention_lines], run_time=tracker.duration / 2)
            self.wait(tracker.duration / 4)

        # Cleaning: Clear all objects
        self.clear()

    def play_scene_4(self):
        # Implementation: Setting dark background
        self.camera.background_color = "#000000"
        # Implementation: Part 1
        with self.voiceover(text="A Transformer has two main parts: an Encoder and a Decoder.") as tracker:
            # Implementation: Draw two large rectangular blocks side-by-side in the center of the screen, each about 200 pixels wide and 100 pixels high, spaced 40 pixels apart.
            # Thinking: Center can be achieved by using ORIGIN and shifting left and right for each block.
            encoder_block = Rectangle(width=4, height=2).move_to(LEFT * 3)
            decoder_block = Rectangle(width=4, height=2).move_to(RIGHT * 3)

            # Implementation: Label the left block "Encoder" and the right block "Decoder" in white Arial font, size 36pt, centered within each block.
            encoder_label = Text("Encoder", font="Arial", font_size=36).move_to(encoder_block)
            decoder_label = Text("Decoder", font="Arial", font_size=36).move_to(decoder_block)

            # Implementation: Add a brief text description below each block in white Arial font, size 24pt: "Encoder: Processes the input sequence." and "Decoder: Generates the output sequence."
            encoder_description = Text("Encoder: Processes the input sequence.", font="Arial", font_size=24).next_to(encoder_block, DOWN)
            decoder_description = Text("Decoder: Generates the output sequence.", font="Arial", font_size=24).next_to(decoder_block, DOWN)

            # Implementation: These descriptions should be horizontally centered with their respective blocks and placed about 20 pixels below.
            encoder_description.align_to(encoder_block, DOWN)
            decoder_description.align_to(decoder_block, DOWN)

            self.play(
                Create(encoder_block),
                Create(decoder_block),
                Write(encoder_label),
                Write(decoder_label),
                Write(encoder_description),
                Write(decoder_description),
                run_time = tracker.duration
            )

        # Cleaning: No object should be cleared

        # Implementation: Part 2
        with self.voiceover(text="The Encoder processes the input sequence. Each Encoder layer has two sub-layers: Multi-Head Self-Attention and a Feed-Forward Network.") as tracker:
            # Implementation: Emphasize the "Encoder" block by increasing its size by 10% and changing its border color to a brighter white.
            self.play(
                encoder_block.animate.scale(1.1).set_stroke(color=WHITE, width=6),
                run_time=tracker.duration / 4
            )

            # Implementation: Divide the "Encoder" block into two distinct horizontal layers.
            line = Line(encoder_block.get_top(), encoder_block.get_bottom())
            line.move_to(encoder_block.get_center())

            # Implementation: Label the top layer "Multi-Head Attention" and the bottom layer "Feed-Forward Network" in white Arial font, size 24pt, centered within each layer.
            multi_head_attention_label = Text("Multi-Head Attention", font="Arial", font_size=24).move_to(encoder_block.get_top() + DOWN * 0.5)
            feed_forward_label = Text("Feed-Forward Network", font="Arial", font_size=24).move_to(encoder_block.get_bottom() + UP * 0.5)

            # Implementation: Use different background colors to distinguish the layers: light grey (#D3D3D3) for "Multi-Head Attention" and slightly darker grey (#A9A9A9) for "Feed-Forward Network".
            multi_head_attention_layer = SurroundingRectangle(multi_head_attention_label, color=LIGHT_GREY, fill_opacity=1, buff=0.3)
            feed_forward_layer = SurroundingRectangle(feed_forward_label, color=DARK_GREY, fill_opacity=1, buff=0.3)

            # Implementation: Add a brief text description below each layer, outside the block: "Multi-Head Attention: Computes attention scores between words." and "Feed-Forward Network: Processes each word's representation." in white Arial font, size 20pt.
            multi_head_attention_description = Text("Multi-Head Attention: Computes attention scores between words.", font="Arial", font_size=20).next_to(encoder_block, DOWN, buff=0.5).shift(UP*0.5)
            feed_forward_description = Text("Feed-Forward Network: Processes each word's representation.", font="Arial", font_size=20).next_to(multi_head_attention_description, DOWN)

            # Implementation: These descriptions should be horizontally centered with their respective layers.
            multi_head_attention_description.align_to(encoder_block, LEFT)
            feed_forward_description.align_to(encoder_block, LEFT)

            self.play(
                Create(multi_head_attention_layer),
                Create(feed_forward_layer),
                Write(multi_head_attention_label),
                Write(feed_forward_label),
                Write(multi_head_attention_description),
                Write(feed_forward_description),
                run_time=tracker.duration / 2
            )
            self.wait(tracker.duration / 4)

        # Cleaning: Clear all objects
        self.clear()

    def play_scene_5(self):
        # Implementation: Setting dark background
        self.camera.background_color = "#000000"
        # Implementation: Part 1
        with self.voiceover(text="In Multi-Head Attention, words are first converted into embeddings.") as tracker:
            # Implementation: Display the sentence "I love learning" at the top-left of the screen, using white Arial font, size 24pt, with words spaced 20 pixels apart.
            # Thinking: Top-left can be achieved by using UP and LEFT direction with some scaling.
            sentence = Text("I love learning", font="Arial", font_size=24).to_edge(UP + LEFT)
            for i in range(len(sentence) - 1):
                sentence[i].next_to(sentence[i+1], RIGHT, buff=0.2)
            self.play(Write(sentence))

            # Implementation: Below each word, draw a vertical array of numbers enclosed in brackets to represent its word embedding.
            embeddings = [
                [0.2, 0.8, -0.1],
                [0.5, -0.3, 0.7],
                [-0.2, 0.6, 0.4]
            ]
            embedding_texts = []
            for i, word in enumerate(sentence):
                # Implementation: Each number should be in white Arial font, size 18pt.
                embedding_text = Matrix(np.array(embeddings[i]).reshape(-1, 1), h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18))
                embedding_text.next_to(word, DOWN)
                embedding_texts.append(embedding_text)
            self.play(*[Write(embedding_text) for embedding_text in embedding_texts], run_time=tracker.duration / 2)

            # Implementation: Label this group of vectors as "Word Embeddings" on the right, using white Arial font, size 24pt, positioned vertically centered with the embeddings.
            # Thinking: Right can be achieved by using RIGHT direction with some scaling.
            word_embeddings_label = Text("Word Embeddings", font="Arial", font_size=24).to_edge(RIGHT)
            word_embeddings_label.align_to(embedding_texts[1], direction=LEFT)
            self.play(Write(word_embeddings_label))
            self.wait(tracker.duration / 2)

        # Cleaning: No object should be cleared

        # Implementation: Part 2
        with self.voiceover(text="Then, for each word, we create Query, Key, and Value vectors using different learned weight matrices.") as tracker:
            # Implementation: For each word embedding, draw three arrows pointing to three new sets of vectors.
            qkv_vectors = []
            qkv_labels = []
            qkv_matrices = []
            for i, embedding_text in enumerate(embedding_texts):
                # Implementation: Each arrow should be 50 pixels long.
                q_arrow = Arrow(embedding_text.get_bottom(), embedding_text.get_bottom() + DOWN * 1.5, buff=0, color=RED)
                k_arrow = Arrow(embedding_text.get_bottom(), embedding_text.get_bottom() + DOWN * 1.5 + LEFT, buff=0, color=BLUE)
                v_arrow = Arrow(embedding_text.get_bottom(), embedding_text.get_bottom() + DOWN * 1.5 + RIGHT, buff=0, color=GREEN)
                qkv_arrows = [q_arrow, k_arrow, v_arrow]

                # Implementation: Label these new vectors as "Query (Q)", "Key (K)", and "Value (V)" using white Arial font, size 20pt, positioned above each vector.
                q_label = Text("Query (Q)", font="Arial", font_size=20, color=RED).next_to(q_arrow.get_end(), UP)
                k_label = Text("Key (K)", font="Arial", font_size=20, color=BLUE).next_to(k_arrow.get_end(), UP)
                v_label = Text("Value (V)", font="Arial", font_size=20, color=GREEN).next_to(v_arrow.get_end(), UP)
                qkv_labels_text = [q_label, k_label, v_label]

                # Implementation: Use different colors for these vectors and their labels: red (#FF0000) for Q, blue (#0000FF) for K, and green (#00FF00) for V.
                q_vector = Matrix(np.array([0.1, 0.2, 0.3]).reshape(-1, 1), h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=RED))
                k_vector = Matrix(np.array([0.4, 0.5, 0.6]).reshape(-1, 1), h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=BLUE))
                v_vector = Matrix(np.array([0.7, 0.8, 0.9]).reshape(-1, 1), h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=GREEN))
                qkv_vector_objects = [q_vector, k_vector, v_vector]

                for j, vec in enumerate(qkv_vector_objects):
                    vec.next_to(qkv_arrows[j].get_end(), DOWN)

                # Implementation: Represent the linear transformations as matrix multiplications.
                wq_matrix = Matrix([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=RED))
                wk_matrix = Matrix([[0.9, 0.8, 0.7], [0.6, 0.5, 0.4], [0.3, 0.2, 0.1]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=BLUE))
                wv_matrix = Matrix([[0.2, 0.3, 0.4], [0.5, 0.6, 0.7], [0.8, 0.9, 0.1]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=GREEN))
                qkv_matrix_objects = [wq_matrix, wk_matrix, wv_matrix]

                # Implementation: Show a matrix labeled Wq (in red) multiplying the word embedding to get Q, Wk (in blue) to get K, and Wv (in green) to get V.
                for j, mat in enumerate(qkv_matrix_objects):
                    mat.next_to(embedding_text, DOWN).shift(0.5 * DOWN + (j - 1) * RIGHT * 2)

                # Implementation: Each matrix should be represented by a 2x3 grid of numbers in their respective colors, using Arial font, size 18pt.
                # Implementation: These labels should be clearly placed beside each transformation arrow.
                wq_label = Text("Wq", font="Arial", font_size=20, color=RED).next_to(wq_matrix, LEFT)
                wk_label = Text("Wk", font="Arial", font_size=20, color=BLUE).next_to(wk_matrix, LEFT)
                wv_label = Text("Wv", font="Arial", font_size=20, color=GREEN).next_to(wv_matrix, LEFT)
                qkv_matrix_labels = [wq_label, wk_label, wv_label]

                self.play(
                    *[Create(arrow) for arrow in qkv_arrows],
                    *[Write(label) for label in qkv_labels_text],
                    *[Write(vec) for vec in qkv_vector_objects],
                    *[Write(mat) for mat in qkv_matrix_objects],
                    *[Write(label) for label in qkv_matrix_labels],
                    run_time=tracker.duration / 3
                )
                qkv_vectors.append(qkv_vector_objects)
                qkv_labels.append(qkv_labels_text)
                qkv_matrices.extend(qkv_matrix_objects)

        # Cleaning: No object should be cleared

        # Implementation: Part 3
        with self.voiceover(text="We calculate the attention scores using scaled dot product of Q and K, normalize them using softmax, and then weight the Value vectors by these scores.") as tracker:
            # Implementation: Illustrate the Scaled Dot-Product Attention process step-by-step.
            attention_score_matrices = []
            normalized_score_matrices = []
            weighted_value_vectors = []
            for i in range(len(sentence)):
                # Implementation: First, show the matrix multiplication of Q (red) and the transpose of K (blue) for a given word, resulting in a 3x3 matrix of attention scores.
                q_vector = qkv_vectors[i][0]
                k_vector = qkv_vectors[i][1]
                attention_score_matrix = Matrix([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18))
                attention_score_matrix.next_to(q_vector, DOWN).align_to(q_vector, LEFT)
                self.play(
                    q_vector.animate.set_color(RED),
                    k_vector.animate.set_color(BLUE),
                    Write(attention_score_matrix),
                    run_time=tracker.duration / 5
                )

                # Implementation: Next, show this matrix being divided by the square root of the dimension of K (e.g., √3), with the result displayed below.
                sqrt_dk = np.sqrt(k_vector.mob_matrix.shape[0])
                scaled_attention_score_matrix = Matrix([[0.06, 0.12, 0.17], [0.23, 0.29, 0.35], [0.41, 0.46, 0.52]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.2f}", font="Arial", font_size=18))
                scaled_attention_score_matrix.next_to(attention_score_matrix, DOWN)
                self.play(Write(scaled_attention_score_matrix), run_time=tracker.duration / 5)

                # Implementation: Then, apply the softmax function to this result, normalizing the scores, and display the final 3x3 matrix with normalized values.
                normalized_score_matrix = Matrix([[0.1, 0.2, 0.7], [0.3, 0.4, 0.3], [0.5, 0.3, 0.2]], h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18))
                normalized_score_matrix.next_to(scaled_attention_score_matrix, DOWN)
                self.play(Write(normalized_score_matrix), run_time=tracker.duration / 5)

                # Implementation: Finally, show the multiplication of these normalized scores with the V (green) vectors to get the weighted Value vectors.
                v_vector = qkv_vectors[i][2]
                weighted_value_vector = Matrix(np.array([0.1, 0.2, 0.3]).reshape(-1, 1), h_buff=0.8, v_buff=0.8, element_to_mobject=lambda x: Text(f"{x:.1f}", font="Arial", font_size=18, color=GREEN))
                weighted_value_vector.next_to(normalized_score_matrix, DOWN)
                self.play(
                    v_vector.animate.set_color(GREEN),
                    Write(weighted_value_vector),
                    run_time=tracker.duration / 5
                )

                attention_score_matrices.append(attention_score_matrix)
                normalized_score_matrices.append(normalized_score_matrix)
                weighted_value_vectors.append(weighted_value_vector)

        # Cleaning: No object should be cleared

        # Implementation: Part 4
        with self.voiceover(text="Each of these is called an attention head, and having multiple of them allows the model to learn different relationships in the data. The outputs of all attention heads are concatenated and multiplied by another weight matrix.") as tracker:
            # Implementation: Illustrate the concept of multiple attention heads by showing three parallel sets of Q, K, and V vectors being generated from the initial word embeddings.
            multi_head_qkv_vectors = []
            multi_head_attention_outputs = []
            for head in range(3):
                head_qkv_vectors = []
                head_attention_outputs = []
                for i, embedding_text in enumerate(embedding_texts):
                    # Implementation: Each set should follow the Scaled Dot-Product Attention process outlined in the previous step, including all intermediate matrices.
                    # Implementation: Use distinct colors for each set (e.g., red/blue/green for the first set, orange/purple/lime for the second, yellow/cyan/magenta for the third).
                    if head == 0:
                        colors = [RED, BLUE, GREEN]
                    elif head == 1:
                        colors = [ORANGE, PURPLE, "#32CD32"]
                    else:
                        colors = [YELLOW,